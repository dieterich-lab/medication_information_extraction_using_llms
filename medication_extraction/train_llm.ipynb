{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d981849d",
   "metadata": {},
   "source": [
    "# Training a Llama model for n2c2 information extraction task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2704f79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading neccessary libraries\n",
    "\n",
    "import torch\n",
    "\n",
    "from trl import SFTTrainer\n",
    "from datasets import load_dataset\n",
    "from transformers import TrainingArguments, TextStreamer\n",
    "\n",
    "from unsloth.chat_templates import get_chat_template\n",
    "from unsloth import FastLanguageModel, is_bfloat16_supported\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from pydantic import Field\n",
    "from typing import Optional, List, Union\n",
    "\n",
    "import json\n",
    "from collections import OrderedDict, defaultdict, Counter\n",
    "\n",
    "import pickle\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import dspy\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8a3302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose random seed\n",
    "seed = 123\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dfc533",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29478f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "max_seq_length = 2048\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"meta-llama/Meta-Llama-3.1-8B\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    load_in_4bit=False,\n",
    "    dtype=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8929c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save finte-tuned model to folder\n",
    "refined_model = \"Meta-Llama-3_1-8b_refined_i2b2_pydantic/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843ba3a5",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a812d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading training data\n",
    "with open('./data/n2c2_train.pkl', 'rb') as f:\n",
    "    dataset_train = pickle.load(f)\n",
    "    \n",
    "# Convert data to list of dictionaries\n",
    "train_dict_data = [{'prompt': item.paragraph, 'response': item.answer} for item in dataset_train]\n",
    "\n",
    "# Create a Dataset\n",
    "train_dataset = Dataset.from_pandas(pd.DataFrame(train_dict_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691f7a84",
   "metadata": {},
   "source": [
    "### Convert data to CHATML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b54536f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pydantic object\n",
    "class Medication(BaseModel):\n",
    "    \"\"\"Medication information extracted from the text.\"\"\"\n",
    "    medication: str = Field(description=\"A drug name or an active ingredient.\")\n",
    "    ade: Optional[Union[str, List[str]]] = Field(default=\"\", description=\"Extract adverse drug events from the text. Example: rash, hypotension, thrombocytopenia, toxicity, diarrhea, altered mental status, Rash, Thrombocytopenia, GI bleed, somnolent, etc.\")\n",
    "    strength: Optional[Union[str, List[str]]] = Field(default=\"\", description=\"Extract the strength of the medication from the text. Examples: 100 mg, 10 mg, 5 mg, 20 mg, 40 mg, 25 mg, 500 mg, 10mg, 50 mg, 5mg, etc.\")\n",
    "    frequency: Optional[Union[str, List[str]]] = Field(default=\"\", description=\"Extract the frequency of the medication from the text. Examples: 1-0-0, 1-0-1, daily, 0-0-1, DAILY (Daily), once a day, DAILY, BID, BID (2 times a day), twice a day, etc.\")\n",
    "    duration: Optional[Union[str, List[str]]] = Field(default=\"\", description=\"Extract the duration of the medication from the text. Examples: dauerhaft, pausiert, abgesetzt, f√ºr 12 Monate, B-DATE - B-DATE, Pause, dauerhafte, 14 day, for 7 days, for 10 days, etc.\")\n",
    "    route: Optional[Union[str, List[str]]] = Field(default=\"\", description=\"Extract the route of the medication from the text. Examples: PO, Oral, IV, by mouth, po, Inhalation, oral, drip, gtt, i.v., etc.\")\n",
    "    form: Optional[Union[str, List[str]]] = Field(default=\"\", description=\"Extract the form of the medication from the text. Examples: Tablet, Capsule, Solution, Tablet, Delayed Release (E.C.), Tablets, Tablet, Chewable, tablet, Appl, Capsule, Delayed Release(E.C.), Tablet(s), etc.\")\n",
    "    dosage: Optional[Union[str, List[str]]] = Field(default=\"\", description=\"Extract the dosage of the medication from the text. Examples: One (1), Two (2), 1, 1-2, 2, sliding scale, Three (3), 0.5, taper, 3, etc.\")\n",
    "    reason: Optional[Union[str, List[str]]] = Field(default=\"\", description=\"Extract the reason of the medication from the text. Examples: pain, Antikoagulation, constipation, Thrombozytenaggregationshemmung, Stentverschlussprophylaxe, anxiety, pneumonia, Antibiose, duale Thrombozytenaggregationshemmung, wheezing, etc.\")\n",
    "\n",
    "class MedicationInfo(BaseModel):\n",
    "    \"\"\"A list of medication information extracted from the text.\"\"\"\n",
    "    medications: List[Medication] = Field(default_factory=list, description=\"A list of medications and their related information.\")\n",
    "\n",
    "schema = json.dumps(MedicationInfo.model_json_schema())\n",
    "\n",
    "# Define system message\n",
    "system_message = f\"\"\"You are a physician. Your task is to extract ALL drug names (active ingredients or drug names) and their related information, such as ADE, strength, frequency, duration, route, form, dosage, and reason from a given text snippet of a doctoral letter. \n",
    "Please make sure to extract the medications **in the order they appear** in the text. Maintain this order in the JSON response.\n",
    "If a medication occurs more than once in the text, append a unique count in parentheses to its name, starting from (1). \n",
    "If there is NO medication information in the text, create a this JSON: {{'medications': []}}\n",
    "ONLY respond with an instance of JSON without any additional information. You have access to a JSON schema, which will determine how the JSON should be structured.\n",
    "Make sure to return ONLY an instance of the JSON, NOT the schema itself. Do not add any additional information.\n",
    "JSON schema:\n",
    "{schema}\n",
    "\"\"\"\n",
    "\n",
    "# Define conversation format\n",
    "def create_conversation(sample):\n",
    "    conversation = {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_message}, \n",
    "            {\"role\": \"user\", \"content\": sample[\"prompt\"]}, \n",
    "            {\"role\": \"assistant\", \"content\": sample[\"response\"]}  \n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    return conversation\n",
    "\n",
    "# Apply the conversation function to the dataset\n",
    "train_chat_dataset = train_dataset.map(create_conversation, remove_columns=['prompt', 'response'])\n",
    "\n",
    "tokenizer = get_chat_template(\n",
    "    tokenizer,\n",
    "    chat_template=\"chatml\",\n",
    ")\n",
    "\n",
    "# Apply the CHATML format\n",
    "def apply_template(examples):\n",
    "    messages = examples[\"messages\"]\n",
    "    text = [tokenizer.apply_chat_template(message, tokenize=False, add_generation_prompt=False) for message in messages]\n",
    "    return {\"text\": text}\n",
    "\n",
    "final_train = train_chat_dataset.map(apply_template, batched=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70dd127",
   "metadata": {},
   "source": [
    "## Train the model and save to folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb6fb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"up_proj\", \"down_proj\", \"o_proj\", \"gate_proj\"], \n",
    "    use_rslora=True,\n",
    "    use_gradient_checkpointing=\"unsloth\"\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=final_train,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    dataset_num_proc=2,\n",
    "    packing=True,\n",
    "    args=TrainingArguments(\n",
    "        learning_rate=3e-4,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        per_device_train_batch_size=4,\n",
    "        gradient_accumulation_steps=2,\n",
    "        num_train_epochs=1,\n",
    "        fp16=not is_bfloat16_supported(),\n",
    "        bf16=is_bfloat16_supported(),\n",
    "        logging_steps=100,\n",
    "        optim=\"adamw_8bit\",\n",
    "        weight_decay=0.01,\n",
    "        warmup_steps=10,\n",
    "        output_dir=refined_model,\n",
    "        seed=0,\n",
    "        save_steps=100,\n",
    "        save_total_limit=2,         \n",
    "        save_strategy=\"steps\",      \n",
    "    ),\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "trainer.model.save_pretrained(refined_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UNSLOTH",
   "language": "python",
   "name": "unsloth"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
